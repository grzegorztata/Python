{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2abf750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/albumentations-team/albumentations\n",
    "# Augmentacja danych to proces generowania różnorodnych wariantów danych treningowych poprzez wprowadzanie różnych \n",
    "# transformacji do oryginalnych przykładów. W kontekście obrazów może to obejmować operacje takie jak obracanie, \n",
    "# skalowanie, przycinanie, zmiana jasności i kontrastu, dodawanie szumu, zmiana odcieni kolorów itp. \n",
    "# Augmentacja jest szczególnie przydatna, gdy masz ograniczoną ilość danych treningowych, ponieważ pomaga stworzyć \n",
    "# różnorodność przykładów, co może poprawić zdolność modelu do generalizacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16a7b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import albumentations as A\n",
    "import cv2 as cv\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b75e1922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47ce8234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
      "60000 train set\n",
      "10000 test set\n",
      "y = 0 T-shirt/top\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b8eab8d810>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print training set shape - note there are 60,000 training data of image size of 28x28, 60,000 train labels)\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_test.shape[0], 'test set')\n",
    "\n",
    "# Define the text labels\n",
    "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Pullover\",     # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Sneaker\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9\n",
    "\n",
    "# Image index, you can pick any number between 0 and 59,999\n",
    "img_index = 1\n",
    "# y_train contains the lables, ranging from 0 to 9\n",
    "label_index = y_train[img_index]\n",
    "# Print the label, for example 2 Pullover\n",
    "print (\"y = \" + str(label_index) + \" \" +(fashion_mnist_labels[label_index]))\n",
    "# # Show one of the images from the training dataset\n",
    "plt.imshow(x_train[img_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d22f0d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5352b74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data - 60000\n",
      "Number of test data - 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train data - \" + str(len(x_train)))\n",
    "print(\"Number of test data - \" + str(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "786dec75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (55000, 28, 28, 1) y_train shape: (55000, 10)\n",
      "55000 train set\n",
      "5000 validation set\n",
      "10000 test set\n"
     ]
    }
   ],
   "source": [
    "# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
    "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
    "\n",
    "# Reshape input data from (28, 28) to (28, 28, 1)\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Print training set shape\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training, validation, and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_valid.shape[0], 'validation set')\n",
    "print(x_test.shape[0], 'test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74487529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 32)        8224      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1568)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               401664    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 412778 (1.57 MB)\n",
      "Trainable params: 412778 (1.57 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2158140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e15f0021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 45s 51ms/step - loss: 0.6018 - accuracy: 0.7779 - val_loss: 0.3697 - val_accuracy: 0.8684\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 46s 54ms/step - loss: 0.4080 - accuracy: 0.8516 - val_loss: 0.3288 - val_accuracy: 0.8820\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 52s 60ms/step - loss: 0.3697 - accuracy: 0.8649 - val_loss: 0.2938 - val_accuracy: 0.8946\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 56s 65ms/step - loss: 0.3406 - accuracy: 0.8750 - val_loss: 0.2787 - val_accuracy: 0.8978\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 53s 62ms/step - loss: 0.3230 - accuracy: 0.8810 - val_loss: 0.2647 - val_accuracy: 0.9008\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 52s 61ms/step - loss: 0.3060 - accuracy: 0.8877 - val_loss: 0.2605 - val_accuracy: 0.9030\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 48s 56ms/step - loss: 0.2933 - accuracy: 0.8919 - val_loss: 0.2441 - val_accuracy: 0.9090\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 51s 59ms/step - loss: 0.2858 - accuracy: 0.8936 - val_loss: 0.2413 - val_accuracy: 0.9114\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 55s 64ms/step - loss: 0.2719 - accuracy: 0.8997 - val_loss: 0.2372 - val_accuracy: 0.9140\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 53s 62ms/step - loss: 0.2671 - accuracy: 0.9010 - val_loss: 0.2238 - val_accuracy: 0.9202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b8e24dfd50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217d3b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
